from __future__ import print_function, division
from google.colab import drive
drive.mount('/content/drive')

!pip install pydicom

import os
import glob
import numpy as np
import cv2 as cv
import skimage.io as io
import skimage.transform as trans
import matplotlib.pyplot as plt
import pydicom
import skimage
from skimage import exposure, io, color, transform
from skimage.util import random_noise
from scipy.ndimage import zoom
from datetime import datetime
import shutil

from keras.preprocessing.image import ImageDataGenerator
from keras import backend as keras
from keras.models import *
from keras.layers import *
from keras.optimizers import *
from keras.callbacks import ModelCheckpoint, LearningRateScheduler

r = [
"/content/drive/MyDrive/MR/CHAOSestratto/Train_Sets/MR/1/T1DUAL/DICOM_anon/InPhase","/content/drive/MyDrive/MR/CHAOSestratto/Train_Sets/MR/1/T1DUAL/DICOM_anon/OutPhase",
"/content/drive/MyDrive/MR/CHAOSestratto/Train_Sets/MR/2/T1DUAL/DICOM_anon/InPhase","/content/drive/MyDrive/MR/CHAOSestratto/Train_Sets/MR/2/T1DUAL/DICOM_anon/OutPhase",
"/content/drive/MyDrive/MR/CHAOSestratto/Train_Sets/MR/3/T1DUAL/DICOM_anon/InPhase","/content/drive/MyDrive/MR/CHAOSestratto/Train_Sets/MR/3/T1DUAL/DICOM_anon/OutPhase",
"/content/drive/MyDrive/MR/CHAOSestratto/Train_Sets/MR/5/T1DUAL/DICOM_anon/InPhase","/content/drive/MyDrive/MR/CHAOSestratto/Train_Sets/MR/5/T1DUAL/DICOM_anon/OutPhase",
"/content/drive/MyDrive/MR/CHAOSestratto/Train_Sets/MR/8/T1DUAL/DICOM_anon/InPhase","/content/drive/MyDrive/MR/CHAOSestratto/Train_Sets/MR/8/T1DUAL/DICOM_anon/OutPhase",
"/content/drive/MyDrive/MR/CHAOSestratto/Train_Sets/MR/10/T1DUAL/DICOM_anon/InPhase","/content/drive/MyDrive/MR/CHAOSestratto/Train_Sets/MR/10/T1DUAL/DICOM_anon/OutPhase",
"/content/drive/MyDrive/MR/CHAOSestratto/Train_Sets/MR/13/T1DUAL/DICOM_anon/InPhase","/content/drive/MyDrive/MR/CHAOSestratto/Train_Sets/MR/13/T1DUAL/DICOM_anon/OutPhase",
"/content/drive/MyDrive/MR/CHAOSestratto/Train_Sets/MR/15/T1DUAL/DICOM_anon/InPhase","/content/drive/MyDrive/MR/CHAOSestratto/Train_Sets/MR/15/T1DUAL/DICOM_anon/OutPhase",
"/content/drive/MyDrive/MR/CHAOSestratto/Train_Sets/MR/19/T1DUAL/DICOM_anon/InPhase","/content/drive/MyDrive/MR/CHAOSestratto/Train_Sets/MR/19/T1DUAL/DICOM_anon/OutPhase",
"/content/drive/MyDrive/MR/CHAOSestratto/Train_Sets/MR/20/T1DUAL/DICOM_anon/InPhase","/content/drive/MyDrive/MR/CHAOSestratto/Train_Sets/MR/20/T1DUAL/DICOM_anon/OutPhase",
"/content/drive/MyDrive/MR/CHAOSestratto/Train_Sets/MR/21/T1DUAL/DICOM_anon/InPhase","/content/drive/MyDrive/MR/CHAOSestratto/Train_Sets/MR/21/T1DUAL/DICOM_anon/OutPhase",
"/content/drive/MyDrive/MR/CHAOSestratto/Train_Sets/MR/22/T1DUAL/DICOM_anon/InPhase","/content/drive/MyDrive/MR/CHAOSestratto/Train_Sets/MR/22/T1DUAL/DICOM_anon/OutPhase",
"/content/drive/MyDrive/MR/CHAOSestratto/Train_Sets/MR/31/T1DUAL/DICOM_anon/InPhase","/content/drive/MyDrive/MR/CHAOSestratto/Train_Sets/MR/31/T1DUAL/DICOM_anon/OutPhase",
"/content/drive/MyDrive/MR/CHAOSestratto/Train_Sets/MR/32/T1DUAL/DICOM_anon/InPhase","/content/drive/MyDrive/MR/CHAOSestratto/Train_Sets/MR/32/T1DUAL/DICOM_anon/OutPhase",
"/content/drive/MyDrive/MR/CHAOSestratto/Train_Sets/MR/33/T1DUAL/DICOM_anon/InPhase","/content/drive/MyDrive/MR/CHAOSestratto/Train_Sets/MR/33/T1DUAL/DICOM_anon/OutPhase",
"/content/drive/MyDrive/MR/CHAOSestratto/Train_Sets/MR/34/T1DUAL/DICOM_anon/InPhase","/content/drive/MyDrive/MR/CHAOSestratto/Train_Sets/MR/34/T1DUAL/DICOM_anon/OutPhase",
"/content/drive/MyDrive/MR/CHAOSestratto/Train_Sets/MR/36/T1DUAL/DICOM_anon/InPhase","/content/drive/MyDrive/MR/CHAOSestratto/Train_Sets/MR/36/T1DUAL/DICOM_anon/OutPhase",
"/content/drive/MyDrive/MR/CHAOSestratto/Train_Sets/MR/37/T1DUAL/DICOM_anon/InPhase","/content/drive/MyDrive/MR/CHAOSestratto/Train_Sets/MR/37/T1DUAL/DICOM_anon/OutPhase",
"/content/drive/MyDrive/MR/CHAOSestratto/Train_Sets/MR/38/T1DUAL/DICOM_anon/InPhase","/content/drive/MyDrive/MR/CHAOSestratto/Train_Sets/MR/38/T1DUAL/DICOM_anon/OutPhase",
"/content/drive/MyDrive/MR/CHAOSestratto/Train_Sets/MR/39/T1DUAL/DICOM_anon/InPhase","/content/drive/MyDrive/MR/CHAOSestratto/Train_Sets/MR/39/T1DUAL/DICOM_anon/OutPhase",]

maschere =[
"/content/drive/MyDrive/MR/CHAOSestratto/Train_Sets/MR/1/T1DUAL/Ground", "/content/drive/MyDrive/MR/CHAOSestratto/Train_Sets/MR/2/T1DUAL/Ground","/content/drive/MyDrive/MR/CHAOSestratto/Train_Sets/MR/3/T1DUAL/Ground",
"/content/drive/MyDrive/MR/CHAOSestratto/Train_Sets/MR/5/T1DUAL/Ground", "/content/drive/MyDrive/MR/CHAOSestratto/Train_Sets/MR/8/T1DUAL/Ground", "/content/drive/MyDrive/MR/CHAOSestratto/Train_Sets/MR/10/T1DUAL/Ground",
"/content/drive/MyDrive/MR/CHAOSestratto/Train_Sets/MR/13/T1DUAL/Ground", "/content/drive/MyDrive/MR/CHAOSestratto/Train_Sets/MR/15/T1DUAL/Ground", "/content/drive/MyDrive/MR/CHAOSestratto/Train_Sets/MR/19/T1DUAL/Ground",
"/content/drive/MyDrive/MR/CHAOSestratto/Train_Sets/MR/20/T1DUAL/Ground", "/content/drive/MyDrive/MR/CHAOSestratto/Train_Sets/MR/21/T1DUAL/Ground","/content/drive/MyDrive/MR/CHAOSestratto/Train_Sets/MR/22/T1DUAL/Ground",
"/content/drive/MyDrive/MR/CHAOSestratto/Train_Sets/MR/31/T1DUAL/Ground", "/content/drive/MyDrive/MR/CHAOSestratto/Train_Sets/MR/32/T1DUAL/Ground", "/content/drive/MyDrive/MR/CHAOSestratto/Train_Sets/MR/33/T1DUAL/Ground",
"/content/drive/MyDrive/MR/CHAOSestratto/Train_Sets/MR/34/T1DUAL/Ground", "/content/drive/MyDrive/MR/CHAOSestratto/Train_Sets/MR/36/T1DUAL/Ground","/content/drive/MyDrive/MR/CHAOSestratto/Train_Sets/MR/37/T1DUAL/Ground",
"/content/drive/MyDrive/MR/CHAOSestratto/Train_Sets/MR/38/T1DUAL/Ground",  "/content/drive/MyDrive/MR/CHAOSestratto/Train_Sets/MR/39/T1DUAL/Ground"
]


def dicom_to_array(dicom_path):
    dicom_image = pydicom.dcmread(dicom_path)
    image_array = dicom_image.pixel_array
    return image_array.astype(float)

def png_to_array(png_path):
    image = Image.open(png_path).convert('L')  #converte in scala di grigi
    return np.array(image)

def save_array_as_png(array, output_path):
    #normalizza i valori dell'array a 0-255 e converte in uint8
    array = (array - np.min(array)) / (np.max(array) - np.min(array)) * 255
    array = array.astype(np.uint8)
    image = Image.fromarray(array)
    image.save(output_path)

def resize_and_resample(array, target_shape, ordine):
    zoom_factors = np.array(target_shape) / np.array(array.shape)
    return zoom(array, zoom_factors, order=ordine)

def rename_images(folder_path):
    files = [f for f in os.listdir(folder_path) if f.endswith('.png')]
    files.sort()
    for i, filename in enumerate(files, start=1):
        old_path = os.path.join(folder_path, filename)
        new_filename = f'image_{i}.png'
        new_path = os.path.join(folder_path, new_filename)
        os.rename(old_path, new_path)

def process_images(dicom_folder, mask_folder, output_dicom_folder, output_mask_folder, new_shape):
    if not os.path.exists(output_dicom_folder):
        os.makedirs(output_dicom_folder)
    if not os.path.exists(output_mask_folder):
        os.makedirs(output_mask_folder)

    dicom_files = [f for f in os.listdir(dicom_folder) if f.endswith('.dcm')]
    mask_files = [f for f in os.listdir(mask_folder) if f.endswith('.png')]

    if len(dicom_files) != len(mask_files):
        print("Il numero di file DICOM non corrisponde al numero di file PNG.")

    for dicom_file, mask_file in zip(dicom_files, mask_files):
        dicom_path = os.path.join(dicom_folder, dicom_file)
        mask_path = os.path.join(mask_folder, mask_file)

        dicom_array = dicom_to_array(dicom_path)
        mask_array = png_to_array(mask_path)

        resized_dicom_array = resize_and_resample(dicom_array, new_shape, 3)
        resized_mask_array = resize_and_resample(mask_array, new_shape, 0)

        output_dicom_path = os.path.join(output_dicom_folder, os.path.splitext(dicom_file)[0] + '.png')
        output_mask_path = os.path.join(output_mask_folder, mask_file)

        save_array_as_png(resized_dicom_array, output_dicom_path)
        save_array_as_png(resized_mask_array, output_mask_path)

    return output_dicom_folder, output_mask_folder



def rename_and_move_pngs(src_folder, dest_folder):
    if not os.path.exists(src_folder):
        print(f"La cartella sorgente {src_folder} non esiste.")
        return
    if not os.path.exists(dest_folder):
        print(f"La cartella di destinazione {dest_folder} non esiste.")
        return

    png_files = [f for f in os.listdir(src_folder) if f.endswith('.png')]
    dest_png_files = [f for f in os.listdir(dest_folder) if f.endswith('.png')]
    j = len(dest_png_files) + 1

    for file_name in png_files:
        src_file = os.path.join(src_folder, file_name)
        new_file_name = f"image_{j}.png"
        dest_file = os.path.join(dest_folder, new_file_name)
        shutil.copy2(src_file, dest_file)
        j += 1


#ciclo per ciascuna cartella di ogni paziente con interpolatore di ordine 3 e di ordine 0 per le maschere
for i in range(2*20):
  dicom_folder = r[i]
  mask_folder = maschere[int(i/2)]
  print(i)
  print(r[i])
  print(mask_folder)
  output_dicom_folder = f'/content/drive/MyDrive/pngfiniti/img{i}'
  output_mask_folder = f'/content/drive/MyDrive/pngfiniti/mask{i}'
  new_shape = (192,192)  # Nuova forma desiderata per le immagini
  output_dicom_folder, output_mask_folder = process_images(dicom_folder, mask_folder, output_dicom_folder, output_mask_folder, new_shape)
  rename_images(output_dicom_folder)
  rename_images(output_mask_folder)

  print(f"Immagini DICOM salvate in: {output_dicom_folder}")
  print(f"Maschere salvate in: {output_mask_folder}")
  print("---")


#per creare delle cartelle con tutti i png del training (sia per immagini che per maschere)
i = 0
for i in range(39):
  dicom_folder = f'/content/drive/MyDrive/pngfiniti/img{i+1}'
  mask_folder = f'/content/drive/MyDrive/pngfiniti/mask{i+1}'
  print(i)
  output_dicom_folder = '/content/drive/MyDrive/pngfiniti1/imgtrain'
  output_mask_folder = '/content/drive/MyDrive/pngfiniti1/masktrain'
  if not os.path.exists(output_dicom_folder):
          os.makedirs(output_dicom_folder)
  if not os.path.exists(output_mask_folder):
          os.makedirs(output_mask_folder)
  rename_and_move_pngs(dicom_folder,output_dicom_folder)
  rename_and_move_pngs(mask_folder,output_mask_folder)


fegato = [128,128,128]
milza = [128,0,0]
renesx = [192,192,128]
renedx = [128,64,128]
sfondo = [0,0,0]

COLOR_DICT = np.array([fegato,milza,renesx,renedx,sfondo])

def trainGenerator(batch_size, train_path, image_folder, mask_folder, aug_dict, image_color_mode="grayscale",
                   mask_color_mode="grayscale", image_save_prefix="image", mask_save_prefix="mask",
                   flag_multi_class=False, num_class=5, save_to_dir=None, target_size=(192,192), seed=1):

    image_datagen = ImageDataGenerator(**aug_dict)
    mask_datagen = ImageDataGenerator(**aug_dict)
    image_generator = image_datagen.flow_from_directory(
        train_path,
        classes=[image_folder],
        class_mode=None,
        color_mode=image_color_mode,
        target_size=target_size,
        batch_size=batch_size,
        save_to_dir=save_to_dir,
        save_prefix=image_save_prefix,
        seed=seed)
    mask_generator = mask_datagen.flow_from_directory(
        train_path,
        classes=[mask_folder],
        class_mode=None,
        color_mode=mask_color_mode,
        target_size=target_size,
        batch_size=batch_size,
        save_to_dir=save_to_dir,
        save_prefix=mask_save_prefix,
        seed=seed)
    train_generator = zip(image_generator, mask_generator)

    return train_generator

def testGenerator(test_path, num_image=30, target_size=(192,192), flag_multi_class=False, as_gray=True):
    for i in range(num_image):
        img = io.imread(os.path.join(test_path, "image_%d.png" % i), as_gray=as_gray)
        img = img / 255
        img = trans.resize(img, target_size)
        img = np.reshape(img, img.shape + (1,)) if not flag_multi_class else img
        img = np.reshape(img, (1,) + img.shape)
        yield img

def geneTrainNpy(image_path, mask_path, flag_multi_class=False, num_class=5, image_prefix="image", mask_prefix="mask", image_as_gray=True, mask_as_gray=True):
    image_name_arr = glob.glob(os.path.join(image_path, "%s*" %image_prefix))
    image_arr = []
    mask_arr = []
    for index, item in enumerate(image_name_arr):
        img = io.imread(item, as_gray=image_as_gray)
        img = np.reshape(img, img.shape + (1,)) if image_as_gray else img
        mask = io.imread(item.replace(image_path, mask_path).replace(image_prefix, mask_prefix), as_gray=mask_as_gray)
        mask = np.reshape(mask, mask.shape + (1,)) if mask_as_gray else mask
        image_arr.append(img)
        mask_arr.append(mask)
    image_arr = np.array(image_arr)
    mask_arr = np.array(mask_arr)

    return image_arr, mask_arr

def labelVisualize(num_class, color_dict, img):
    img = img[:, :, 0] if len(img.shape) == 3 else img
    img_out = np.zeros(img.shape + (3,))
    for i in range(num_class):
        img_out[img == i, :] = color_dict[i]

    return img_out / 255

def saveResult(save_path, npyfile, flag_multi_class=False, num_class=5):
    for i, item in enumerate(npyfile):
        img = labelVisualize(num_class, COLOR_DICT, item) if flag_multi_class else item[:, :, 0]
        io.imsave(os.path.join(save_path, "%d_predict.png" % i), img)

def unet(pretrained_weights=None, input_size=(192,192,1)):
    inputs = Input(input_size)
    conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(inputs)
    conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv1)
    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)
    conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool1)
    conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv2)
    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)
    conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool2)
    conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv3)
    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)
    conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool3)
    conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv4)
    drop4 = Dropout(0.5)(conv4)
    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)

    conv5 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool4)
    conv5 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv5)
    drop5 = Dropout(0.5)(conv5)

    up6 = Conv2D(512, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(drop5))
    merge6 = concatenate([drop4, up6], axis=3)
    conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge6)
    conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv6)

    up7 = Conv2D(256, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(conv6))
    merge7 = concatenate([conv3, up7], axis=3)
    conv7 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge7)
    conv7 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv7)

    up8 = Conv2D(128, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(conv7))
    merge8 = concatenate([conv2, up8], axis=3)
    conv8 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge8)
    conv8 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv8)

    up9 = Conv2D(64, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(conv8))
    merge9 = concatenate([conv1, up9], axis=3)
    conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge9)
    conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)
    conv9 = Conv2D(2, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)
    conv10 = Conv2D(1, 1, activation='sigmoid')(conv9)

    model = Model(inputs=inputs, outputs=conv10)

    model.compile(optimizer=Adam(learning_rate=1e-4), loss='binary_crossentropy', metrics=['accuracy'])

    if pretrained_weights:
        model.load_weights(pretrained_weights)

    return model

train_path = '/content/drive/MyDrive/pngfiniti1/'
image_folder = 'imgtrain'
mask_folder = 'masktrain'

data_gen_args = dict()

myGene = trainGenerator(5, train_path, image_folder, mask_folder, data_gen_args, save_to_dir=None)
model = unet()
model_checkpoint = ModelCheckpoint('unet_membrane_no_aug.hdf5', monitor='loss', verbose=1, save_best_only=True)
model.fit(myGene, steps_per_epoch=150, epochs=5, callbacks=[model_checkpoint])
